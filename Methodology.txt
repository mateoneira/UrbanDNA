DATABASE:

Python libraries: pandas, numpy, requests, os, json, overpy

The data was extracted from OpenStreetMap via Overpass API and Overpass-Turbo. The programming language used by Overpass-Turbo is parallel to XML with some differences. In this website the user can construct a query and extract the raw file as a JSON, GEOJSON or XML. The data was extracted as a JSON in parts to make smaller queries. In each query the area was predefined as London and the query was done for nodes (direct lat lon coordinates) and for ways (polygons composed of nodes indicating buildings, parks, etc). Amenity, Shop, Tourism and Leisure were extracted as both: nodes and ways. Though the data was fairly clean, it was necessary to iterate every row and extract amenity type from ‘tags’, as well as coordinates for ways. The way query contains coordinates for the centre of the polygon which where extracted in the same iteration. 

Additional cleaning was necessary after joining all tables together to delete amenities that are not pertinent for this study: amenities where no interaction amongst humans exist even if these provide a service such as: atm, vending_machine, post_box, waste_bin, picnic_table. Initially it was decided to label these as urban furniture but discarded later on. 

After the cleaning a new column was created to further categorise groups of amenities for example: college, school, kindergarten, as education. health_clinic, hospital, as health. town_hall, parliament as government, etc. 

Additional data was also downloaded from the london store site. Data containing population at ward level, jobs in the area (indicating day population), income, house prices and public transport accessibility score.

The data was uploaded to MySQL in two separate tables (amenities and london_info) for the rest of the study. 


DATA ANALYSIS:

The programming language used is Python and libraries like pandas, numpy, scipy, scikit, shapely, matplotlib etc.

- Clustering Methods (THIS IS COPIED FROM MY REPORT, PLEASE PARAPHRASE)

we are testing three different density based clustering methods to identify neighborhood scale agglomerations of amenities. We start by using the Density Based Spatial Clustering Algorithm with Noise (DBSCAN) and then we tested Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN), which is based on DBSCAN but you don’t need to specify the epsilon distance around each point and also it allows for varying density clusters. At the end, we examined the Agglomerative Clustering method where each point begins in its own cluster and then merge with others ones based on different criteria. The method that meets our needs for this study is HDBSCAN as it creates attractive neighbourhoods that correspond successfully to most of the amenities concentrations in London.

In addition to the three density based clustering methods, we also implemented a clustering method based on effective number of amenities introduced by Hidalgo & Castañer in their …(2015). Specifically, we first calculate the effective number of amenities ($A_i$) of each amenity i (i.e. sum of i’s 2000 nearest neighboring amenities whose contribute to $A_i$ is adjusted by distance decay). Based on $A_i$, we proceed to identify the neighborhood center (local maxima) by comparing $A_i$ with its $n_i$ nearest neighbor’s effective number of amenities. Afterwards, we assign the rest of the amenities to each neighborhood center iteratively (see Hedalgo, will expand / clarify further). [after the actual result] The result (see fig. viz) shows shows meaningful neighborhood identification.

Reference:
Hidalgo, C. A., & Castañer, E. E. (2015). The amenity space and the evolution of neighborhoods. arXiv Preprint arXiv:1509.02868. Retrieved from https://arxiv.org/abs/1509.02868

- Clustering Boundaries (THIS IS COPIED FROM MY REPORT, PLEASE PARAPHRASE)

Now that we have our amenities in clusters we need to define the spatial boundaries of those neighbourhoods, ie. the area occupied by a set of points within a cluster in order to check local variables of that specific area. The first attempt was made by determining the convex hull of our points which does not always represent the actual outline of the cluster because it does not take into account concave polygons. Therefore, we studied the concept of alpha shape which is based on Delaunay triangulation and is capable of constructing non-convex enclosure on a group of points.


- Spearman’s Rank Correlation Coefficient (THIS IS COPIED FROM MY REPORT, PLEASE PARAPHRASE)

Having the identified clusters in London we examine the probability for the amenities to be co-located in the same cluster by investigating the spearman’s rank correlation coefficient which calculates the strength and direction of association between two ranked variables.


- Hierarchical Clustering (THIS IS COPIED FROM MY REPORT, PLEASE PARAPHRASE)

Our aim is to group the different clusters together based on their most popular amenities in order to create fewer sets of clusters that share similar types and populations of amenities. To do so, we focus on the different clusters and we deal with them as if they were points with multi-dimensional coordinates which in our case would be the populations of the different amenities. The main purpose of using Hierarchical clustering is that it enables us to determine manually the number of clusters by choosing a distance cut-off, plotted on the dendrogram, and then name those clusters based on the amenities that they share.

- Interpolation

At this point we have two sets of polygons: one derived from our identified neighborhoods using various clustering methods, and the other inherited from artificially drawn census unit (e.g. OA for TDAl, LSOA for demographics). The former is our unit of study (# what’s the term called?), but the latter contains the socio-economic attributes data of our interest. In order to solve the boundary discrepancy, we employed area interpolation.i.e. interpolating attribute data from census unit (source area) to identified neighborhood (target area). We used an area-based volume-preserving method called overlay interpretation (Lam, 2009). In details, for each target area we have calculated its area composition of one or more source areas. After being weighted by such overlaying area, each source area’s attribute value has been summed to return the attribute value of the target area.

Reference:
Lam, N. S. (2009). Spatial Interpolation. In R. Kitchin & N. Thrift (Eds.), International Encyclopedia of Human Geography (pp. 369–376). Oxford: Elsevier. https://doi.org/10.1016/B978-008044910-4.00530-7


- Diversity Index

Drawing heavily from ecology literature where Shannon’s Entropy and Simpson’s indices have been widely used to quantify biodiversity (Gorelick, 2006), we treated each type of amenity as species and calculated alpha (i.e. local) diversity for each neighborhood we identified. (+ interpretation of the two indices)

Reference:
Gorelick, R. (2006). Combining richness and abundance into a single diversity index using matrix analogues of Shannon’s and Simpson’s indices. Ecography, 29(4), 525–530. https://

doi.org/10.1111/j.0906-7590.2006.04601.x




WEBSITE:

The website was built using bootstrap framework, this allowed the implementation of responsive elements that adapt to different devices. The CSS files from bootstrap were modified to change colors and fonts of different elements, additional CSS files were created to style the sidebar which contained all the graphs. 
For the visualization two separate javascript files were created, one contains all the functions to create an interactive map, the other contains all the functions to graph the pertinent data to the sidebar. When the webpage loads, a call different API's endpoints are made, the data is recieved in JSON format and parsed to a data array that is used for the various visualizations.


API:

The API was create using NODE js. Three different endpoints were created. The /amenities/:type/:lat/:lon/:radius requires the specification of type of amenity, latitude, longitude and radius, and gives back all the amenities that satisfiy the parameters, if type is set to "all" the API returns all amenities within specified area. If type = 'summary', the API returns a JSON containing the different amenity types and their corresponding frequency. 
The /aSpace endpoint does not requiere any specification and returns the results from a spearman rank correlation in the form of list adjacency matrix. 

